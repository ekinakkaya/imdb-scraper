{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class IMDBLinkScraper:\n",
    "    root_search_url = \"https://www.imdb.com/search/title/?\"\n",
    "\n",
    "    # we will add this to the link with the formatting: ?release_date=2024-10-03,2024-10-03\n",
    "    release_date_query = \"&release_date=\"\n",
    "\n",
    "    # the problem is that there are a lot of movies. for example there are 4,711 movies\n",
    "    # in the day of 01-01-2023 and 2,719,230 movies in the year 2023 alone\n",
    "    # so if we think about it, even if we only fetch the day 01-01-2023, there will be 4711 movies.\n",
    "    # and IMDb made the search page in a way that it only shows 50 of the movies initially\n",
    "    # and you have to click the \"Show More\" button to see 50 more movies. so we would need to click\n",
    "    # 4711 / 50 times which is 95 clicks. lets say if every click and fetch takes 5 seconds. 95 x 5 = 471 seconds.\n",
    "    # almost 8 minutes. for a day of movies. what? anyways we'll just test and see\n",
    "    \n",
    "    # what we will do is that we will first check every year individually and save the number of movies for that year\n",
    "    # then we will calculate how should we adjust the release date parameter\n",
    "\n",
    "    SCRAPING_MODES = [\"DAY\", \"MONTH\", \"YEAR\"]\n",
    "    # if the year has > 500.000 movies, scraping mode will be DAY\n",
    "    # if the year has > 50.000 movies, scraping mode will be MONTH\n",
    "    # if the year has > 5.000 movies, scraping mode will be YEAR\n",
    "\n",
    "    scraped_imdb_movie_links = []\n",
    "\n",
    "    yearly_counts_file_path = \"yearly_counts.json\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = Logger(\"imdb_link_scraper.log\").getLogger()\n",
    "        self.logger.info(\"starting IMDB Link scraper\")\n",
    "\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.wait = WebDriverWait(self.driver, 5)\n",
    "        self.logger.info(\"initialized IMDb link scraper with \" + self.driver.name + \" driver.\")\n",
    "\n",
    "    def navigate(self, url):\n",
    "        self.driver.get(url)\n",
    "        self.logger.info(\"navigated to \" + url)\n",
    "\n",
    "    def create_search_query(self, start_date, end_date):\n",
    "        return self.root_search_url + self.release_date_query + start_date + \",\" + end_date\n",
    "\n",
    "    def read_yearly_movie_counts_file(self, filename):\n",
    "        data_normalized = {}\n",
    "\n",
    "        with open(filename, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            # we normalize the date while reading the file\n",
    "            data_normalized[\"updated_at\"] = datetime.datetime.strptime(data[\"updated_at\"], \"%Y-%m-%d\")\n",
    "            data_normalized[\"yearly_counts\"] = {}\n",
    "\n",
    "            for year in data[\"yearly_counts\"]:\n",
    "                data_normalized[\"yearly_counts\"][year] = data[\"yearly_counts\"][year]\n",
    "        \n",
    "        return data_normalized\n",
    "\n",
    "    def write_yearly_movie_counts_file(self, filename, updated_at: any, yearly_counts):\n",
    "        today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        data_structured = {\n",
    "            \"updated_at\": today,\n",
    "            \"yearly_counts\": yearly_counts\n",
    "        }\n",
    "\n",
    "        with open(filename, \"w\") as file:\n",
    "            self.logger.info(\"writing the yearly movie counts to JSON file: \" + filename + \" with indent=2. updated_at=\" + updated_at)\n",
    "            json.dump(data_structured, file, indent=2)\n",
    "\n",
    "    # from 1800 to this day, fetch how many movies are there in every year\n",
    "    # this is for understanding the data and how we should proceed fetching it\n",
    "    def fetch_yearly_movie_count(self, start_year: int, end_year: int):\n",
    "        # if a yearly_counts.json file exists and it is not older than 7 days, we just return the yearly_counts\n",
    "\n",
    "        if (os.path.exists(self.yearly_counts_file_path)):\n",
    "            self.logger.info(\"a yearly_counts.json file already exists. checking if it is viable\")\n",
    "\n",
    "            data = self.read_yearly_movie_counts_file(self.yearly_counts_file_path)\n",
    "\n",
    "            updated_at = data[\"updated_at\"] # this is already in datetime format\n",
    "            now = datetime.datetime.now()\n",
    "            seven_days_ago = now - datetime.timedelta(days=7)\n",
    "\n",
    "            if updated_at > seven_days_ago:\n",
    "                if str(start_year) in data[\"yearly_counts\"] and str(end_year) in data[\"yearly_counts\"]:\n",
    "                    self.logger.info(\"yearly_counts.json file is viable. returning the data\")\n",
    "                    return data\n",
    "                else:\n",
    "                    self.logger.warning(\"yearly_counts.json file does not contain the needed years. going to start fetching new data\")\n",
    "            else:\n",
    "                self.logger.info(\"yearly_counts.json file is older than 7 days. going to start fetching new data\")\n",
    "        else:\n",
    "            self.logger.info(\"yearly_counts.json file does not exist. going to start fetching it\")\n",
    "            \n",
    "                \n",
    "        yearly_counts: dict = {}\n",
    "        \n",
    "        for year in range(start_year, end_year + 1):\n",
    "            movie_count: int = 0\n",
    "            \n",
    "            start_date = str(year) + \"-01-01\"\n",
    "            end_date = str(int(year + 1)) + \"-01-01\"\n",
    "\n",
    "            self.logger.info(\"fetching movie count for interval: \" + start_date + \" | \" + end_date)\n",
    "\n",
    "            self.navigate(self.create_search_query(start_date, end_date))\n",
    "            self.driver.implicitly_wait(10)\n",
    "\n",
    "            movie_count_element_list = self.driver.find_elements(by=By.XPATH, value=\"//*[@id=\\\"__next\\\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[1]/div[1]\")\n",
    "            if (movie_count_element_list != []):\n",
    "                movie_count_text: str = movie_count[0].text\n",
    "                if movie_count_text == \"\":\n",
    "                    movie_count = 0\n",
    "                else:\n",
    "                    movie_count = int(movie_count.split(\"of \")[1].replace(\",\", \"\"))\n",
    "                \n",
    "                print(\"movie count for year \" + str(year) + \": \" + str(movie_count))\n",
    "                self.logger.info(\"found movie count for interval: \" + start_date + \" | \" + end_date + \" is \" + str(movie_count))\n",
    "            else:\n",
    "                movie_count = 0\n",
    "                print(\"movie count unknown for year \" + str(year))\n",
    "                self.logger.warning(\"movie count unknown for year \" + str(year))\n",
    "\n",
    "            yearly_counts[year] = movie_count\n",
    "\n",
    "        self.logger.info(\"finished fetching movie counts for years \" + str(start_year) + \" to \" + str(end_year))\n",
    "\n",
    "        self.logger.info(\"writing the yearly movie counts to JSON file.\")\n",
    "\n",
    "        self.write_yearly_movie_counts_file(self.yearly_counts_file_path, yearly_counts)\n",
    "\n",
    "        self.driver.quit()\n",
    "\n",
    "        \n",
    "    # TODO: do some refactoring\n",
    "\n",
    "    # TODO: make a yearly movie count class inside this class\n",
    "    \n",
    "    # TODO: make a method that creates a scrape path. a scrape path will be a list of dates for the program to scrape while scraping the actual movies.\n",
    "    # explanation: the yearly_counts.json file contains the yearly counts.\n",
    "    # if the yearly count is > 500000, the scraping mode will be DAY.\n",
    "    # and the program will create a series of days for scraping. like:\n",
    "    # [\"2024-01-01,2024-01-01\", \"2024-01-02,2024-01-02\", ...]\n",
    "    # if it was monthly, it wwould be like this:\n",
    "    # [\"2024-01-01,2024-01-31\", \"2024-02-01,2024-02-29\"]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = IMDBLinkScraper()\n",
    "yearly_counts_data = scraper.fetch_yearly_movie_count(2000, 2024)\n",
    "\n",
    "# turn yearly_counts into a json file\n",
    "# add the todays date to the file itself\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
